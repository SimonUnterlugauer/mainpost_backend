{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from darts import TimeSeries\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from mlflow import MlflowClient \n",
    "from mlflow.models import infer_signature\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(r\"C:\\Users\\jakob\\Downloads\\archive (1)\\AirPassengers.csv\")\n",
    "\n",
    "ab_df = pd.read_csv('../../data/interim/absences_per_day.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_df = ab_df[['index', 'count']]\n",
    "# drop all rows with index older than 2023-03-01\n",
    "ab_df = ab_df.drop(ab_df[ab_df['index'] > '2023-03-01'].index)\n",
    "# normalize data   \n",
    "#ab_df['count'] = ab_df['count'] / ab_df['count'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.004082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.004082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.004082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0.002041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>0.002041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>2023-02-25</td>\n",
       "      <td>0.440816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>2023-02-26</td>\n",
       "      <td>0.138776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>0.232653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0.234694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>0.216327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1155 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index     count\n",
       "0    2020-01-02  0.004082\n",
       "1    2020-01-03  0.004082\n",
       "2    2020-01-04  0.004082\n",
       "3    2020-01-05  0.002041\n",
       "4    2020-01-06  0.002041\n",
       "...         ...       ...\n",
       "1150 2023-02-25  0.440816\n",
       "1151 2023-02-26  0.138776\n",
       "1152 2023-02-27  0.232653\n",
       "1153 2023-02-28  0.234694\n",
       "1154 2023-03-01  0.216327\n",
       "\n",
       "[1155 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#series = TimeSeries.from_dataframe(df, 'Month', '#Passengers')\n",
    "#series = TimeSeries.from_dataframe(df, 'Month', '#Passengers')\n",
    "#series\n",
    "#creaet new dataframe with only date and count\n",
    "ab_df['index'] = pd.to_datetime(ab_df['index'])\n",
    "\n",
    "series = TimeSeries.from_dataframe(ab_df, 'index', 'count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from darts.models import ExponentialSmoothing\n",
    "\n",
    "#train_ts, test_ts = series.split_before(pd.Timestamp('20220701'))\n",
    "\n",
    "#model = ExponentialSmoothing()\n",
    "#model.fit(train_ts)\n",
    "#prediction = model.predict(len(test_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#series.plot(label='actual')\n",
    "#prediction.plot(label='forecast', lw=3)\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import ExponentialSmoothing\n",
    "from darts.models import Prophet\n",
    "\n",
    "\n",
    "#models = [ExponentialSmoothing(), Prophet()]\n",
    "\n",
    "models = [ExponentialSmoothing()]\n",
    "\n",
    "backtests = [model.historical_forecasts(series,\n",
    "                            start=.7,\n",
    "                            forecast_horizon=3)\n",
    "             for model in models]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_train_ts, single_test_ts = series.split_before(pd.Timestamp('2023-01-01'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.dataprocessing.transformers import Scaler, StaticCovariatesTransformer\n",
    "\n",
    "pipeline = Scaler()\n",
    "#pipeline = Pipeline([Scaler(), StaticCovariatesTransformer()]) # MinMaxScaler\n",
    "train_dataset_ts_prepared = pipeline.fit_transform(single_train_ts)\n",
    "test_dataset_ts_prepared = pipeline.transform(single_test_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizons = len(single_test_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'output_chunk_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m model_ExponentialSmoothing \u001b[39m=\u001b[39m ExponentialSmoothing(output_chunk_length\u001b[39m=\u001b[39m\u001b[39m356\u001b[39m, \n\u001b[0;32m      2\u001b[0m                             random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m      3\u001b[0m                             multi_models\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m                                          \u001b[39m#'transformer': Scaler()}\u001b[39;00m\n\u001b[0;32m     10\u001b[0m                             )\n\u001b[1;32m---> 12\u001b[0m model_ExponentialSmoothing\u001b[39m.\u001b[39;49mfit(series\u001b[39m=\u001b[39;49mtrain_dataset_ts_prepared)\n\u001b[0;32m     13\u001b[0m prediction_ExponentialSmoothing \u001b[39m=\u001b[39m model_ExponentialSmoothing\u001b[39m.\u001b[39mpredict(n\u001b[39m=\u001b[39mforecast_horizons, series\u001b[39m=\u001b[39mtrain_dataset_ts_prepared)\n\u001b[0;32m     14\u001b[0m prediction_ExponentialSmoothing \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39minverse_transform(prediction_ExponentialSmoothing)\n",
      "File \u001b[1;32mc:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\darts\\models\\forecasting\\exponential_smoothing.py:106\u001b[0m, in \u001b[0;36mExponentialSmoothing.fit\u001b[1;34m(self, series)\u001b[0m\n\u001b[0;32m     95\u001b[0m     seasonal_periods_param \u001b[39m=\u001b[39m \u001b[39m12\u001b[39m\n\u001b[0;32m     97\u001b[0m hw_model \u001b[39m=\u001b[39m hw\u001b[39m.\u001b[39mExponentialSmoothing(\n\u001b[0;32m     98\u001b[0m     series\u001b[39m.\u001b[39mvalues(copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m     99\u001b[0m     trend\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrend \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrend \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrend\u001b[39m.\u001b[39mvalue,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m     dates\u001b[39m=\u001b[39mseries\u001b[39m.\u001b[39mtime_index \u001b[39mif\u001b[39;00m series\u001b[39m.\u001b[39mhas_datetime_index \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    105\u001b[0m )\n\u001b[1;32m--> 106\u001b[0m hw_results \u001b[39m=\u001b[39m hw_model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_kwargs)\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m hw_results\n\u001b[0;32m    109\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer_seasonal_periods:\n",
      "File \u001b[1;32mc:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'output_chunk_length'"
     ]
    }
   ],
   "source": [
    "model_ExponentialSmoothing = ExponentialSmoothing(lags=2, \n",
    "                            output_chunk_length=356, \n",
    "                            random_state=0,\n",
    "                            multi_models=False, \n",
    "                            #lags_past_covariates=past_lags,\n",
    "                            #lags_future_covariates=future_lags,\n",
    "                            add_encoders={\"cyclic\": {\"future\": [\"month\"]}, \n",
    "                                         'datetime_attribute': {'future': ['dayofweek']},\n",
    "                                         'position': {'past': ['relative'], 'future': ['relative']},}\n",
    "                                         #'transformer': Scaler()}\n",
    "                            )\n",
    "\n",
    "model_ExponentialSmoothing.fit(series=train_dataset_ts_prepared)\n",
    "prediction_ExponentialSmoothing = model_ExponentialSmoothing.predict(n=forecast_horizons, series=train_dataset_ts_prepared)\n",
    "prediction_ExponentialSmoothing = pipeline.inverse_transform(prediction_ExponentialSmoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prophet = Prophet.predict(n=forecast_horizons, series = train_ts)\n",
    "#prediction_prophet = pipeline.inverse_transform(prediction_lightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.metrics import mape\n",
    "\n",
    "series.plot(label='data')\n",
    "for i, m in enumerate(models):\n",
    "    err = mape(backtests[i], series)\n",
    "    backtests[i].plot(lw=3, label='{}, MAPE={:.2f}%'.format(m, err))\n",
    "\n",
    "plt.title('Backtesting results')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('./mlruns')\n",
    "mlflow.set_experiment('singlets')\n",
    "experiment = mlflow.get_experiment_by_name('singlets')\n",
    "client = MlflowClient()\n",
    "\n",
    "run = client.create_run(experiment.experiment_id)\n",
    "\n",
    "with mlflow.start_run(run_id=run.info.run_id) as run:\n",
    "\n",
    "    (rmse, mae, r2) = eval_metrics(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.prophet.log_model(prophet, 'model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
